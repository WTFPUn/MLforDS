{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Connected Components. Non-programming exercise. Label the following image with colors starting 1.\n",
    "a. 5 points. 0.5 hrs. Use 4 connected to label the background (white) regions. Show the equivalence\n",
    "table and the final color in each box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "5 points. 0.5 hrs. Use 4 connected to label the background (white) regions. Show the equivalence\n",
    "table and the final color in each box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4-connected background labeling\n",
    "<br>\n",
    "<img src=\"./Q3/2_1_a/4connnectback.jpg\"/>\n",
    "- 8-connected background labeling\n",
    "<br>\n",
    "<img src=\"./Q3/2_1_a/8connectback.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "5 points. 0.5 hrs. Use 8 connected to label foreground (black) regions. Show the equivalence table\n",
    "and the final color in each box.\n",
    "\n",
    "- 4-connected foreground labeling\n",
    "<br>\n",
    "<img src=\"./Q3/2_1_a/4connnectfore.jpg\"/>\n",
    "\n",
    "- 8-connected foreground labeling\n",
    "<br>\n",
    "\n",
    "<img src=\"./Q3/2_1_a/8connectfore.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "Handwritten Digit Recognition. Use the digits.png file as templates for digits 0, 1, …, 9. Write\n",
    " a python program to cut out each digit as a labeled dataset from 0..9, each of which is 20x20. Note: You\n",
    " may also use this exact same dataset with 100 samples of each digit 0..9 using 20 x 20 pixels from the\n",
    " internet along with libraries to read/load the dataset, if that’s easier for you.\n",
    " Load all the character data into a python class. Then rescale each character from 20 x 20 to 24 x 24 using\n",
    " OpenCV. Use 80% of the data as the training set, reserving 20% for testing.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from typing import TypedDict, List, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(TypedDict):\n",
    "    zero: List[np.ndarray]\n",
    "    one: List[np.ndarray]\n",
    "    two: List[np.ndarray]\n",
    "    three: List[np.ndarray]\n",
    "    four: List[np.ndarray]\n",
    "    five: List[np.ndarray]\n",
    "    six: List[np.ndarray]\n",
    "    seven: List[np.ndarray]\n",
    "    eight: List[np.ndarray]\n",
    "    nine: List[np.ndarray]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits: Digits = {\n",
    "    \"zero\": [],\n",
    "    \"one\": [],\n",
    "    \"two\": [],\n",
    "    \"three\": [],\n",
    "    \"four\": [],\n",
    "    \"five\": [],\n",
    "    \"six\": [],\n",
    "    \"seven\": [],\n",
    "    \"eight\": [],\n",
    "    \"nine\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplot to see the result\n",
    "import matplotlib.pyplot as plt\n",
    "def crop_image(image: np.ndarray, shape: Tuple[int, int], digits: Digits):\n",
    "  '''\n",
    "  to crop a whole digit image(20*20) from big image and rescale it to 24*24\n",
    "  '''\n",
    "  height, width = shape\n",
    "  print(image.shape)\n",
    "  uncropClass: Digits = {}\n",
    "  for i,key in enumerate(digits.keys()):\n",
    "    print(\"crop from\", 20*i*5 , \"to\", 20*(i+1)*5, \"for\", key)\n",
    "    uncropClass[key] = image[20*i*5:20*(i+1)*5, :]    \n",
    "    print(uncropClass[key].shape)\n",
    "\n",
    "  for key in uncropClass.keys():\n",
    "    class_crop = uncropClass[key]\n",
    "    for i in range(0, class_crop.shape[1], width):\n",
    "      for j in range(0, class_crop.shape[0], height):\n",
    "        crop = class_crop[j:j+height, i:i+width]\n",
    "        if crop.shape[0] == height and crop.shape[1] == width:\n",
    "          digits[key].append(cv2.resize(crop, (24, 24)))\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000, 3)\n",
      "(1000, 2000, 3)\n",
      "crop from 0 to 100 for zero\n",
      "(100, 2000, 3)\n",
      "crop from 100 to 200 for one\n",
      "(100, 2000, 3)\n",
      "crop from 200 to 300 for two\n",
      "(100, 2000, 3)\n",
      "crop from 300 to 400 for three\n",
      "(100, 2000, 3)\n",
      "crop from 400 to 500 for four\n",
      "(100, 2000, 3)\n",
      "crop from 500 to 600 for five\n",
      "(100, 2000, 3)\n",
      "crop from 600 to 700 for six\n",
      "(100, 2000, 3)\n",
      "crop from 700 to 800 for seven\n",
      "(100, 2000, 3)\n",
      "crop from 800 to 900 for eight\n",
      "(100, 2000, 3)\n",
      "crop from 900 to 1000 for nine\n",
      "(100, 2000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 24, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('./Q3/digits.png')\n",
    "print(image.shape)\n",
    "\n",
    "crop_image(image, (20, 20), digits)\n",
    "\n",
    "\n",
    "digits['eight'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea9534a500>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(digits['three'][50], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_digits: Digits = {}\n",
    "test_digits: Digits = {}\n",
    "\n",
    "for key in digits.keys():\n",
    "  train_digits[key], test_digits[key] = train_test_split(digits[key], test_size=0.2, random_state=42)\n",
    "\n",
    "train_digits['eight'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1\n",
    "10+10+10+10 pts. 5 hrs. Then try recognition by using the test images and report the accuracy\n",
    " percent for these 4 (classifier, feature type) combinations: (KNN K = 5, gray scale features),\n",
    " (KNN K =5,HOGfeatures), (KNN K = 1, gray scale features), (KNN K = 1, HOG features). For\n",
    " HOG, use 20° histogram orientations of non-directional gradients (ie., 9 bins) with 16 x 16\n",
    " overlapping pixel windows for each 24 x 24 digit. Each digit will, thus, have 144 HOG features\n",
    " from 4 x 4 x 9, with 9 histogram values x 4 per 16 by 16 block x 4 such blocks per 24 x 24 image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image: Digits, preprocess: Callable[[List[np.ndarray]], List[np.ndarray]]) -> Digits:\n",
    "  '''\n",
    "  to preprocess the image with a given function\n",
    "  '''\n",
    "  result: Digits = {}\n",
    "  for key in image.keys():\n",
    "    result[key] = preprocess(image[key])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KNN K = 5, gray scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea9e729000>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYy0lEQVR4nO3dbWxT5/2H8a+BJKjGgULAIQGl4WloY2NAWYg2SEZWLa1grJrKRl9QugepQFUxTYIybcrYJiFRCZBCqj1TpEqMCsrEiyWBqIUBhTBoB4QVGDSw1klc0mzYQGIXOP8X+9fDK7T4HIefba6PdKTGOT/uu66biwNOjk+SIwAA7rEB1hsAANyfCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAxyHoDt1NSUqJoNGq9DQCAS4FAQB0dHZ94TsYFqKSkRKFQyHobAACPSktLPzFCGRegj658SktLuQoCgCwUCAQUCoU+9Wt4xgXoI9FolAABQA7rtzchLFu2TO3t7ert7dXhw4c1c+bM/loKAJCF+iVACxcu1Pr167VmzRpNnz5dx48fV3Nzs0aOHNkfywEAspST7uPw4cNOfX194mOfz+e89957zqpVqz51NhAIOI7jOIFAIO374uDg4ODo/+Nuv46n/QooLy9PM2bMUEtLS+Ixx3HU0tKiysrKj52fn5+vQCCQdAAAcl/aA1RUVKRBgwYpHA4nPR4Oh1VcXPyx81evXq1IJJI4eAs2ANwfzH8Swtq1a1VYWJg4SktLrbcEALgH0v427O7ubl2/fl3BYDDp8WAwqK6uro+dH4/HFY/H070NAECGS/sV0Icffqhjx46ppqYm8ZjP51NNTY0OHTqU7uUAAFmqX74Rdf369dqyZYuOHj2qI0eOaMWKFfL7/dq8eXN/LAcAyEL9EqBXXnlFI0eO1M9//nMVFxfrb3/7m2pra/X+++/3x3IAgCzk03/ej50xAoGAIpGICgsL+VE8AJCF7vbruPm74AAA9ycCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz0yx1RgfuBz+dzPTt06FDXswMHDnQ9K0m9vb2uZ/v6+jytffPmTU/zyC1cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOB2DLhvFRQUeJofM2aM69l58+a5nh08eLDrWUk6ePCg69k333zT09rXrl3zNI/cwhUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMH9gJDVBg4c6Hp29OjRntb+xje+4Xr2xz/+sevZvr4+17OSt3vynDp1ymxt5B6ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHA7BmS1YcOGuZ6dOXOmp7W///3vu54dMmSI69nTp0+7npWkf/7zn65nr1696mlt4FZcAQEATBAgAIAJAgQAMJH2ANXV1clxnKTj7bffTvcyAIAs1y9vQmhra9PXvva1xMfXr1/vj2UAAFmsXwJ0/fp1hcPh/vilAQA5ol/+DmjixIkKhUI6f/68Xn75ZY0dO/aO5+bn5ysQCCQdAIDcl/YAtba2asmSJaqtrdXSpUtVXl6u/fv33/H7HlavXq1IJJI4QqFQurcEAMhAaQ9QU1OTtm/frpMnT2r37t167LHHNGzYMC1cuPC2569du1aFhYWJo7S0NN1bAgBkoH7/SQiXL1/W2bNnNWHChNt+Ph6PKx6P9/c2AAAZpt+/D8jv92v8+PHq7Ozs76UAAFkk7QF64YUXNGfOHJWVlamyslI7d+7UjRs3tHXr1nQvBQDIYmn/I7gxY8Zo69atGjFihC5duqQDBw5o1qxZ6u7uTvdSAIAslvYALVq0KN2/JAAgB3E7BpjKy8vzND9t2jTXs3d6Z+bd8nJLhba2NtezXm5BIUnjxo1zPfvggw96WptvUMet+GGkAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAT3A4KpiRMnepr/+te/7np2/Pjxntb+3e9+53r23Llzrmd/8IMfuJ6VpLlz57qeDYVCntZ+5ZVXPM0jt3AFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggtsxwNTw4cM9zY8ZM8b1bF5enqe1jx496nr25MmTrmdra2tdz0rS5z73OdezDz30kKe1gVtxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcD8gmLpy5Yqn+Wg06np2wABvv/8KBoOuZy9evOh6dsiQIa5nJSkej7uevXr1qqe1gVtxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYILbMcBUKBTyNP/3v//d9WxFRYWntR999FHXsyNHjnQ9+9nPftb1rCSdPHnS9ezp06c9rQ3ciisgAIAJAgQAMEGAAAAmUg7Q7NmztWvXLoVCITmOowULFnzsnDVr1qijo0PXrl3Tnj17NGHChLRsFgCQO1IOkN/v1/Hjx7V8+fLbfn7lypV67rnn9Mwzz6iiokJXr15Vc3OzCgoKPG8WAJA7Un4XXFNTk5qamu74+RUrVuiXv/yldu3aJUlavHixwuGwvvnNb2rbtm3udwoAyClp/Tug8vJyjR49Wi0tLYnHIpGIWltbVVlZeduZ/Px8BQKBpAMAkPvSGqDi4mJJUjgcTno8HA4nPve/Vq9erUgkkji8fl8IACA7mL8Lbu3atSosLEwcpaWl1lsCANwDaQ1QV1eXJCkYDCY9HgwGE5/7X/F4XNFoNOkAAOS+tAaovb1dnZ2dqqmpSTwWCARUUVGhQ4cOpXMpAECWS/ldcH6/P+n7esrLyzV16lT19PTo3Xff1caNG/WTn/xE//jHP9Te3q5f/OIX6ujo0J/+9Kd07hsAkOVSDtDDDz+svXv3Jj7esGGDJOmll17S008/rXXr1snv9+s3v/mNhg0bpgMHDqi2tlaxWCxtmwYAZL+UA7Rv3z75fL5PPKeurk51dXWuNwUAyH3m74IDANyfuB8QTF26dMnT/NGjR13PfvnLX/a0tpf7AX3+8593PZufn+96VpLeeust17NnzpzxtDZwK66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDsGZLUrV664nvV6K4ghQ4a4np04caLr2T/+8Y+uZyXpL3/5i+vZzs5OT2sDt+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABLdjgKlAIOBpvry83PXspEmTPK3t8/lczw4a5P5/vb6+PtezktTb2+t69saNG57WBm7FFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwf2AYKqsrMzTfEVFhevZoqIiT2vv2LHD9ezIkSNdz06ePNn1rCRVVVW5nu3p6fG09oULFzzNI7dwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYILbMcBUMBj0NF9SUuJ6tru729Pav/3tb13PFhcXu5797ne/63pWkubOnet6tqury9Pa4XDY9Wxvb6+ntZF5uAICAJggQAAAEwQIAGAi5QDNnj1bu3btUigUkuM4WrBgQdLnN2/eLMdxko7Gxsa0bRgAkBtSDpDf79fx48e1fPnyO57T2Nio4uLixLFo0SJPmwQA5J6U3wXX1NSkpqamTzwnFot5ercLACD39cvfAVVXVyscDuv06dN68cUXNXz48Duem5+fr0AgkHQAAHJf2gPU1NSkxYsXq6amRqtWrVJVVZUaGxs1YMDtl1q9erUikUjiCIVC6d4SACADpf0bUbdt25b457a2Np04cULvvPOOqqur9dprr33s/LVr12r9+vWJjwOBABECgPtAv78Nu729XZcuXdKECRNu+/l4PK5oNJp0AAByX78HqLS0VCNGjFBnZ2d/LwUAyCIp/xGc3+9PupopLy/X1KlT1dPTo56eHtXV1WnHjh3q6urS+PHjtW7dOp07d07Nzc1p3TgAILulHKCHH35Ye/fuTXy8YcMGSdJLL72kpUuX6gtf+IKeeuopDRs2TB0dHdq9e7d++tOfKh6Pp23TAIDsl3KA9u3bJ5/Pd8fP19bWetoQAOD+wM+CAwCY4H5AMPVJV9N3IxaLuZ71+saYEydOuJ5tbW11PfvQQw+5npWkxx57zPVsdXW1p7X/+te/up49d+6cp7WRebgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwe0YYOrf//63p/m+vj7Xs+PGjfO09he/+EXXs0eOHHE9+8Ybb7ielaSKigrXs5MnT/a09rRp01zPcjuG3MMVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW7HAFNtbW2e5v/85z+7nh07dqyntevr613P7t271/VsOBx2PStJRUVFrmcHDhzoae0HH3zQ0zxyC1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAT3A4KpWCzmaf7NN990PbtlyxZPay9atMj17LRp01zPDh061PWsJOXl5bmeff311z2t7eW/F3IPV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4HQNMOY7jaf6DDz5wPXvgwAFPa/f09LienTx5suvZoqIi17OSdO3aNdezJ0+e9LT22bNnPc0jt3AFBAAwQYAAACYIEADAREoBev7553XkyBFFIhGFw2Ht3LlTkyZNSjqnoKBAmzZtUnd3t6LRqLZv365Ro0alddMAgOyXUoCqqqrU0NCgWbNm6ZFHHlFeXp52796tBx54IHHOhg0bNH/+fD3xxBOqqqpSSUmJXn311bRvHACQ3VJ6F9yjjz6a9PGSJUt06dIlzZgxQ/v371dhYaG+973v6cknn9Trr78uSXr66ad1+vRpVVRUqLW1NX07BwBkNU9/BzR06FBJ/3076owZM5Sfn6+WlpbEOWfOnNHFixdVWVl5218jPz9fgUAg6QAA5D7XAfL5fNq4caMOHDigU6dOSZKKi4sVi8V0+fLlpHPD4bCKi4tv++usXr1akUgkcYRCIbdbAgBkEdcBamho0JQpU/Sd73zH0wbWrl2rwsLCxFFaWurp1wMAZAdXPwmhvr5e8+bN05w5c5KuWLq6ulRQUKChQ4cmXQUFg0F1dXXd9teKx+OKx+NutgEAyGIpXwHV19fr8ccf19y5c3XhwoWkzx07dkzxeFw1NTWJxyZNmqSysjIdOnTI82YBALkjpSughoYGPfnkk1qwYIGi0aiCwaAk6fLly+rr61MkEtHvf/97rV+/Xj09PYpEIqqvr9cbb7zBO+AAAElSCtCyZcskSfv27Ut6fMmSJdqyZYsk6Yc//KFu3rypHTt2qKCgQM3NzYk5AAA+klKAfD7fp54Ti8X07LPP6tlnn3W9KQBA7uNnwQEATPgkebshS5oFAgFFIhEVFhYqGo1abwe4owED3P/+7dYfX5WqwYMHu56VpBs3brie9XIvIek/f0KC3He3X8e5AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJHSDekA/NfNmzddz165csVkFsgkXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEIOsN3EkgELDeAgDAhbv9+p1xAfpo46FQyHgnAAAvAoGAotHoHT/vk+Tcu+3cnZKSkjtuOhAIKBQKqbS09BP/xfBfPGep4zlLHc9Z6nL5OQsEAuro6PjEczLuCkjSp25akqLRaM79B+tvPGep4zlLHc9Z6nLxObubfx/ehAAAMEGAAAAmsi5AsVhMP/vZzxSLxay3kjV4zlLHc5Y6nrPU3e/PWUa+CQEAkPuy7goIAJAbCBAAwAQBAgCYIEAAABNZF6Bly5apvb1dvb29Onz4sGbOnGm9pYxVV1cnx3GSjrffftt6Wxll9uzZ2rVrl0KhkBzH0YIFCz52zpo1a9TR0aFr165pz549mjBhgsFOM8enPWebN2/+2OuusbHRaLf2nn/+eR05ckSRSEThcFg7d+7UpEmTks4pKCjQpk2b1N3drWg0qu3bt2vUqFFGO753sipACxcu1Pr167VmzRpNnz5dx48fV3Nzs0aOHGm9tYzV1tam4uLixPGVr3zFeksZxe/36/jx41q+fPltP79y5Uo999xzeuaZZ1RRUaGrV6+qublZBQUF93inmePTnjNJamxsTHrdLVq06B7uMLNUVVWpoaFBs2bN0iOPPKK8vDzt3r1bDzzwQOKcDRs2aP78+XriiSdUVVWlkpISvfrqq4a7vnecbDkOHz7s1NfXJz72+XzOe++956xatcp8b5l41NXVOW+99Zb5PrLlcBzHWbBgQdJjHR0dzo9+9KPEx4WFhU5vb6/z7W9/23y/mXDc7jnbvHmzs3PnTvO9ZepRVFTkOI7jzJ4925H+85qKxWLOt771rcQ5n/nMZxzHcZyKigrz/fbnkTVXQHl5eZoxY4ZaWloSjzmOo5aWFlVWVhruLLNNnDhRoVBI58+f18svv6yxY8dabylrlJeXa/To0UmvuUgkotbWVl5zn6K6ulrhcFinT5/Wiy++qOHDh1tvKWMMHTpUktTT0yNJmjFjhvLz85NeZ2fOnNHFixdz/nWWNQEqKirSoEGDFA6Hkx4Ph8MqLi422lVma21t1ZIlS1RbW6ulS5eqvLxc+/fv15AhQ6y3lhU+el3xmktNU1OTFi9erJqaGq1atUpVVVVqbGzUgAFZ8+Wm3/h8Pm3cuFEHDhzQqVOnJP3ndRaLxXT58uWkc++H11lG/jRspEdTU1Pin0+ePKnW1lZdvHhRCxcu1B/+8AfDnSGXbdu2LfHPbW1tOnHihN555x1VV1frtddeM9yZvYaGBk2ZMoW/i/1/WfNbku7ubl2/fl3BYDDp8WAwqK6uLqNdZZfLly/r7Nmz9/27uO7WR68rXnPetLe369KlS/f9666+vl7z5s3TV7/61aQbbnZ1damgoCDxR3MfuR9eZ1kToA8//FDHjh1TTU1N4jGfz6eamhodOnTIcGfZw+/3a/z48ers7LTeSlZob29XZ2dn0msuEAiooqKC11wKSktLNWLEiPv6dVdfX6/HH39cc+fO1YULF5I+d+zYMcXj8aTX2aRJk1RWVnZfvM7M3wlxt8fChQud3t5eZ/Hixc7kyZOdX/3qV05PT48zatQo871l4vHCCy84c+bMccrKypzKykpn9+7dzvvvv+8UFRWZ7y1TDr/f70ydOtWZOnWq4ziOs2LFCmfq1KnO2LFjHUnOypUrnZ6eHmf+/PnOlClTnJ07dzrnz593CgoKzPeeic+Z3+931q1b51RUVDhlZWXO3LlznaNHjzpnzpxx8vPzzfducTQ0NDj/+te/nDlz5jjBYDBxDB48OHHOiy++6Fy4cMGprq52pk+f7hw8eNA5ePCg+d7vwWG+gZSO5cuXOxcuXHD6+vqcw4cPO1/60pfM95Spx9atW51QKOT09fU57777rrN161Zn3Lhx5vvKpKOqqsq5nc2bNyfOWbNmjdPZ2en09vY6e/bscSZOnGi+70x9zgYPHuw0NTU54XDYicViTnt7u/PrX//6vv5N4p089dRTiXMKCgqcTZs2OR988IFz5coVZ8eOHU4wGDTfe38f3I4BAGAia/4OCACQWwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE/8HoikfTQ11EQEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def to_grayscale(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "  '''\n",
    "  to convert the image to grayscale\n",
    "  '''\n",
    "  return [Image.fromarray(image).convert('L') for image in images]\n",
    "\n",
    "grayscale_train_digits = preprocess_image(train_digits, to_grayscale)\n",
    "grayscale_test_digits = preprocess_image(test_digits, to_grayscale)\n",
    "\n",
    "plt.imshow(grayscale_train_digits['eight'][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "K = 5\n",
    "\n",
    "def flatten_images(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "  '''\n",
    "  to flatten the image\n",
    "  '''\n",
    "  return [np.array(image).flatten() for image in images]\n",
    "\n",
    "def train_knn_model(train_images: Digits, K: int) -> KNeighborsClassifier:\n",
    "  '''\n",
    "  to train the knn model\n",
    "  '''\n",
    "  train_images = preprocess_image(train_images, flatten_images)\n",
    "  X = []\n",
    "  y = []\n",
    "  for key in train_images.keys():\n",
    "    X += train_images[key]\n",
    "    y += [key] * len(train_images[key])\n",
    "  model = KNeighborsClassifier(n_neighbors=K)\n",
    "  model.fit(X, y)\n",
    "  return model\n",
    "\n",
    "model = train_knn_model(grayscale_train_digits, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 0.99\n",
      "one 0.99\n",
      "two 0.91\n",
      "three 0.89\n",
      "four 0.92\n",
      "five 0.97\n",
      "six 0.97\n",
      "seven 0.9\n",
      "eight 0.95\n",
      "nine 0.94\n"
     ]
    }
   ],
   "source": [
    "for cls in grayscale_test_digits.keys():\n",
    "  predicts = model.predict(flatten_images(grayscale_test_digits[cls]))\n",
    "  print(cls, np.mean(predicts == cls))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. KNN K =5,HOGfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 1.0\n",
      "one 0.99\n",
      "two 0.96\n",
      "three 0.97\n",
      "four 0.96\n",
      "five 0.94\n",
      "six 0.98\n",
      "seven 0.9\n",
      "eight 0.99\n",
      "nine 0.94\n"
     ]
    }
   ],
   "source": [
    "from cv2 import HOGDescriptor\n",
    "\n",
    "def HOG(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "  '''\n",
    "  to extract the HOG feature from the image\n",
    "  '''\n",
    "  winSize = (24,24) #same as the size of the image\n",
    "  blockSize = (16,16) #OpenCV only supports 16 x 16 block sizes\n",
    "  blockStride = (8,8) #multiple of cell size. Here it is multiple of 1.\n",
    "  cellSize = (8,8) #OpenCV only supports 8x8 cell size. That means each Block will have 4 histograms\n",
    "  nbins = 9 #OpenCV only supports 9 orientations per cell.  That means 1 block has 4 x 9 = 36 features\n",
    "  derivAperture = 1\n",
    "  winSigma = 4.\n",
    "  histogramNormType = 0\n",
    "  L2HysThreshold = 2.0000000000000001e-01\n",
    "  gammaCorrection = 0\n",
    "  hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "                          histogramNormType,L2HysThreshold,gammaCorrection)\n",
    "  \n",
    "  result = []\n",
    "  for image in images:\n",
    "    result.append(hog.compute(np.array(image)))\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def train_knn_model_HOG(train_images: Digits, K: int) -> KNeighborsClassifier:\n",
    "  '''\n",
    "  to train the knn model with HOG feature\n",
    "  '''\n",
    "  train_images = preprocess_image(train_images, HOG)\n",
    "  X = []\n",
    "  y = []\n",
    "  for key in train_images.keys():\n",
    "    X += train_images[key]\n",
    "    y += [key] * len(train_images[key])\n",
    "  model = KNeighborsClassifier(n_neighbors=K)\n",
    "  model.fit(X, y)\n",
    "  return model\n",
    "\n",
    "model_HOG = train_knn_model_HOG(grayscale_train_digits, K)\n",
    "\n",
    "for cls in grayscale_test_digits.keys():\n",
    "  predicts = model_HOG.predict(HOG(grayscale_test_digits[cls]))\n",
    "  print(cls, np.mean(predicts == cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KNN K = 1, gray scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 0.99\n",
      "one 0.99\n",
      "two 0.95\n",
      "three 0.88\n",
      "four 0.94\n",
      "five 0.94\n",
      "six 0.98\n",
      "seven 0.92\n",
      "eight 0.95\n",
      "nine 0.95\n"
     ]
    }
   ],
   "source": [
    "K = 1\n",
    "\n",
    "grayscale_train_digits = preprocess_image(train_digits, to_grayscale)\n",
    "grayscale_test_digits = preprocess_image(test_digits, to_grayscale)\n",
    "\n",
    "model_gray = train_knn_model(grayscale_train_digits, K)\n",
    "\n",
    "for cls in grayscale_test_digits.keys():\n",
    "  predicts = model_gray.predict(flatten_images(grayscale_test_digits[cls]))\n",
    "  print(cls, np.mean(predicts == cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. KNN K = 1, HOG features with use 20° histogram orientations of non-directional gradients (ie., 9 bins) with 16 x 16\n",
    "overlapping pixel windows for each 24 x 24 digit. Each digit will, thus, have 144 HOG features\n",
    "from 4 x 4 x 9, with 9 histogram values x 4 per 16 by 16 block x 4 such blocks per 24 x 24 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 0.99\n",
      "one 0.97\n",
      "two 0.98\n",
      "three 0.98\n",
      "four 0.96\n",
      "five 0.93\n",
      "six 0.97\n",
      "seven 0.95\n",
      "eight 0.97\n",
      "nine 0.95\n"
     ]
    }
   ],
   "source": [
    "def mod_HOG(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "  '''\n",
    "  to extract the HOG feature from the image\n",
    "  '''\n",
    "  winSize = (24,24)\n",
    "  blockSize = (16,16)\n",
    "  blockStride = (8,8)  # Overlapping of 50%\n",
    "  cellSize = (8,8)\n",
    "  nbins = 9  # Number of orientation bins\n",
    "  hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "  hog_descriptors = []\n",
    "  for image in images:\n",
    "      # Ensure the image is a numpy array\n",
    "      if not isinstance(image, np.ndarray):\n",
    "          image = np.array(image)\n",
    "      # Ensure the image is grayscale\n",
    "      if len(image.shape) > 2:\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      hog_descriptor = hog.compute(image)\n",
    "      hog_descriptors.append(hog_descriptor)\n",
    "  return hog_descriptors\n",
    "\n",
    "\n",
    "model_HOG = train_knn_model_HOG(grayscale_train_digits, K)\n",
    "\n",
    "for cls in grayscale_test_digits.keys():\n",
    "    predicts = model_HOG.predict(mod_HOG(grayscale_test_digits[cls]))\n",
    "    print(cls, np.mean(predicts == cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "Use KNN K = 1 with HOG features to report:\n",
    "1. 5 pts. 1.0 hrs. Result for 2 test images per digit 0..9 cropped out from digits.png but not\n",
    "aligned at the original 20 x 20 image, so you may have smaller or bigger input image sizes.\n",
    "You must rescale each test image to 24 x 24 because HOG requires this scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the image from 0-9\n",
    "<br>\n",
    "<img src=\"./Q3/Q2_2_a_datadir.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from image of  0 got:  ['zero']\n",
      "from image of  0 got:  ['zero']\n",
      "from image of  1 got:  ['one']\n",
      "from image of  1 got:  ['four']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  3 got:  ['three']\n",
      "from image of  3 got:  ['three']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  6 got:  ['five']\n",
      "from image of  7 got:  ['seven']\n",
      "from image of  7 got:  ['one']\n",
      "from image of  8 got:  ['eight']\n",
      "from image of  8 got:  ['eight']\n",
      "from image of  9 got:  ['three']\n",
      "from image of  9 got:  ['nine']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for imagename in os.listdir('./Q3/2_2_a/'):\n",
    "  image = cv2.imread('./Q3/2_2_a/' + imagename)\n",
    "  # rescue the image to 24*24\n",
    "  resized_image = cv2.resize(image, (24, 24))\n",
    "  # use the model to predict the image\n",
    "  print(\"from image of \",imagename.split(\"_\")[0], \"got: \", model_HOG.predict(mod_HOG([resized_image])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 5 pts. 1.0 hrs. Result for 2 test images per digit 0..9 you create in a Paint program to see if\n",
    "you can find your character. Each test image should be big to start with such as 50x50, but\n",
    "you should rescale it to 24 x 24 before testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the code that can [write image with tkinter](https://stackoverflow.com/questions/55575685/jupyter-notebook-let-a-user-inputs-a-drawing) and I need to implement it to use only image and not save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import numpy as np\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "black = (255, 255, 255) # canvas back\n",
    "\n",
    "# Create a dictionary to store the images for each digit\n",
    "digit_images = {i: [] for i in range(10)}\n",
    "\n",
    "# Create two empty PIL images and draw objects to draw on\n",
    "output_image1 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "draw1 = ImageDraw.Draw(output_image1)\n",
    "output_image2 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "draw2 = ImageDraw.Draw(output_image2)\n",
    "\n",
    "def save():\n",
    "    global output_image1, output_image2, draw1, draw2\n",
    "    # Save the images and add them to the dictionary\n",
    "    for i, output_image in enumerate([output_image1, output_image2]):\n",
    "        resized_image = output_image.resize((24, 24))\n",
    "        \n",
    "        resized_image = cv2.bitwise_not(np.array(resized_image))\n",
    "\n",
    "        digit_images[digit.get()].append(resized_image)\n",
    "    # Clear the canvases\n",
    "    canvas1.delete(\"all\")\n",
    "    canvas2.delete(\"all\")\n",
    "    # Clear the output images\n",
    "    output_image1 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "    draw1 = ImageDraw.Draw(output_image1)\n",
    "    output_image2 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "    draw2 = ImageDraw.Draw(output_image2)\n",
    "\n",
    "def paint(event, draw):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    event.widget.create_oval(x1, y1, x2, y2, fill=\"black\",width=25)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=20)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# Create a dropdown menu to select the digit\n",
    "digit = IntVar(master)\n",
    "digit.set(0) # default value\n",
    "digit_menu = OptionMenu(master, digit, *range(10))\n",
    "digit_menu.pack()\n",
    "\n",
    "# Create two tkinter canvases to draw on\n",
    "canvas1 = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas1.pack()\n",
    "canvas2 = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas2.pack()\n",
    "\n",
    "\n",
    "\n",
    "canvas1.bind(\"<B1-Motion>\", lambda event: paint(event, draw1))\n",
    "canvas2.bind(\"<B1-Motion>\", lambda event: paint(event, draw2))\n",
    "\n",
    "# Add a button to save the images\n",
    "button=Button(text=\"save\",command=save)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit 0 has 2 images\n",
      "Digit 1 has 2 images\n",
      "Digit 2 has 2 images\n",
      "Digit 3 has 2 images\n",
      "Digit 4 has 2 images\n",
      "Digit 5 has 2 images\n",
      "Digit 6 has 2 images\n",
      "Digit 7 has 2 images\n",
      "Digit 8 has 2 images\n",
      "Digit 9 has 2 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(f\"Digit {i} has {len(digit_images[i])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea9660b130>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit_images[1][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from image of  0 got:  ['six']\n",
      "from image of  0 got:  ['zero']\n",
      "from image of  1 got:  ['one']\n",
      "from image of  1 got:  ['one']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  3 got:  ['seven']\n",
      "from image of  3 got:  ['three']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  7 got:  ['seven']\n",
      "from image of  7 got:  ['seven']\n",
      "from image of  8 got:  ['three']\n",
      "from image of  8 got:  ['three']\n",
      "from image of  9 got:  ['nine']\n",
      "from image of  9 got:  ['nine']\n"
     ]
    }
   ],
   "source": [
    "for i in digit_images.keys():\n",
    "  for j in range(len(digit_images[i])):\n",
    "    print(\"from image of \",i, \"got: \", model_HOG.predict(mod_HOG([digit_images[i][j]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 5 pts. 1.0 hrs. Result for 4 test images of digit 5 you create in Paint with white background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import numpy as np\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "white = (255, 255, 255) # canvas back\n",
    "\n",
    "# Create a dictionary to store the images for each digit\n",
    "digit_images = {i: [] for i in range(10)}\n",
    "\n",
    "# Create two empty PIL images and draw objects to draw on\n",
    "output_image1 = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "draw1 = ImageDraw.Draw(output_image1)\n",
    "output_image2 = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "draw2 = ImageDraw.Draw(output_image2)\n",
    "\n",
    "def save():\n",
    "    global output_image1, output_image2, draw1, draw2\n",
    "    # Save the images and add them to the dictionary\n",
    "    for i, output_image in enumerate([output_image1, output_image2]):\n",
    "        resized_image = output_image.resize((24, 24))\n",
    "        digit_images[digit.get()].append(np.array(resized_image))\n",
    "        output_image.save(f\"digit_{digit.get()}_{i}.png\")\n",
    "    # Clear the canvases\n",
    "    canvas1.delete(\"all\")\n",
    "    canvas2.delete(\"all\")\n",
    "    # Clear the output images\n",
    "    output_image1 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "    draw1 = ImageDraw.Draw(output_image1)\n",
    "    output_image2 = PIL.Image.new(\"RGB\", (width, height), black)\n",
    "    draw2 = ImageDraw.Draw(output_image2)\n",
    "    \n",
    "\n",
    "def paint(event, draw):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    event.widget.create_oval(x1, y1, x2, y2, fill=\"black\",width=25)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=25)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# Create a dropdown menu to select the digit\n",
    "digit = IntVar(master)\n",
    "digit.set(0) # default value\n",
    "digit_menu = OptionMenu(master, digit, *range(10))\n",
    "digit_menu.pack()\n",
    "\n",
    "# Create two tkinter canvases to draw on\n",
    "canvas1 = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas1.pack()\n",
    "canvas2 = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas2.pack()\n",
    "\n",
    "\n",
    "\n",
    "canvas1.bind(\"<B1-Motion>\", lambda event: paint(event, draw1))\n",
    "canvas2.bind(\"<B1-Motion>\", lambda event: paint(event, draw2))\n",
    "\n",
    "# Add a button to save the images\n",
    "button=Button(text=\"save\",command=save)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea96581300>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit_images[8][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from image of  0 got:  ['nine']\n",
      "from image of  0 got:  ['zero']\n",
      "from image of  1 got:  ['one']\n",
      "from image of  1 got:  ['one']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  2 got:  ['two']\n",
      "from image of  3 got:  ['three']\n",
      "from image of  3 got:  ['three']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  4 got:  ['four']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  5 got:  ['five']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  6 got:  ['two']\n",
      "from image of  6 got:  ['seven']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  6 got:  ['six']\n",
      "from image of  7 got:  ['seven']\n",
      "from image of  7 got:  ['seven']\n",
      "from image of  8 got:  ['eight']\n",
      "from image of  8 got:  ['eight']\n",
      "from image of  9 got:  ['four']\n",
      "from image of  9 got:  ['nine']\n"
     ]
    }
   ],
   "source": [
    "for i in digit_images.keys():\n",
    "  for j in range(len(digit_images[i])):\n",
    "    print(\"from image of \",i, \"got: \", model_HOG.predict(mod_HOG([digit_images[i][j]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 \n",
    "20 pts. 2 hrs. For each 0..9 digit in your dataset of 100 characters, use OpenCV’s auto threshold\n",
    "(Otsu’s algorithm) and then the connected components to find the bounding box. Use that\n",
    "bounding box to cut out each original gray-scale image (not the thresholded image) and resize\n",
    "each back to 24 x 24. This will be your new dataset (training and testing, combined). Report the\n",
    "accuracy percent for KNN K = 1 using HOG features. Is the result here better than in problem 2a\n",
    "for KNN = 1 using HOG features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming images is a list of your grayscale images\n",
    "hog_features = []\n",
    "image = cv2.imread('./Q3/digits.png')\n",
    "print(image.shape)\n",
    "uncropClass: Digits = {}\n",
    "for i,key in enumerate(digits.keys()):\n",
    "    uncropClass[key] = image[20*i*5:20*(i+1)*5, :]\n",
    "    # to grayscale\n",
    "    uncropClass[key] = cv2.cvtColor(uncropClass[key], cv2.COLOR_BGR2GRAY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncropClass['zero'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit zero has 505 connected components\n",
      "Digit one has 506 connected components\n",
      "Digit two has 509 connected components\n",
      "Digit three has 517 connected components\n",
      "Digit four has 505 connected components\n",
      "Digit five has 528 connected components\n",
      "Digit six has 505 connected components\n",
      "Digit seven has 509 connected components\n",
      "Digit eight has 507 connected components\n",
      "Digit nine has 515 connected components\n",
      "Digit zero has 504 images\n",
      "Digit one has 505 images\n",
      "Digit two has 508 images\n",
      "Digit three has 516 images\n",
      "Digit four has 504 images\n",
      "Digit five has 527 images\n",
      "Digit six has 504 images\n",
      "Digit seven has 508 images\n",
      "Digit eight has 506 images\n",
      "Digit nine has 514 images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "cropClass: Digits = {\n",
    "    \"zero\": [], \n",
    "    \"one\": [],\n",
    "    \"two\": [],\n",
    "    \"three\": [],\n",
    "    \"four\": [],\n",
    "    \"five\": [],\n",
    "    \"six\": [],\n",
    "    \"seven\": [],\n",
    "    \"eight\": [],\n",
    "    \"nine\": []\n",
    "}\n",
    "\n",
    "\n",
    "for digit, images in uncropClass.items():\n",
    "    # use Otsu's thresholding\n",
    "    _, thresh = cv2.threshold(images, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # use connected component analysis to find the bounding box\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "    print(f\"Digit {digit} has {num_labels} connected components\") \n",
    "    for stat in stats[1:]:\n",
    "        x, y, w, h, area = stat\n",
    "        crop = images[y:y+h, x:x+w]\n",
    "        cropClass[digit].append(cv2.resize(crop, (24, 24)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in cropClass.keys():\n",
    "  print(f\"Digit {i} has {len(cropClass[i])} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 0.9702970297029703\n",
      "one 0.8712871287128713\n",
      "two 0.9215686274509803\n",
      "three 0.9134615384615384\n",
      "four 0.8118811881188119\n",
      "five 0.8679245283018868\n",
      "six 0.9801980198019802\n",
      "seven 0.9313725490196079\n",
      "eight 0.9509803921568627\n",
      "nine 0.9029126213592233\n"
     ]
    }
   ],
   "source": [
    "# HOG\n",
    "def HOG(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "  '''\n",
    "  to extract the HOG feature from the image\n",
    "  '''\n",
    "  winSize = (24,24)\n",
    "  blockSize = (16,16)\n",
    "  blockStride = (8,8)  # Overlapping of 50%\n",
    "  cellSize = (8,8)\n",
    "  nbins = 9  # Number of orientation bins\n",
    "  hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "  hog_descriptors = []\n",
    "  for image in images:\n",
    "      # Ensure the image is a numpy array\n",
    "      if not isinstance(image, np.ndarray):\n",
    "          image = np.array(image)\n",
    "      # Ensure the image is grayscale\n",
    "      if len(image.shape) > 2:\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      hog_descriptor = hog.compute(image)\n",
    "      hog_descriptors.append(hog_descriptor)\n",
    "  return hog_descriptors\n",
    "\n",
    "train_digits: Digits = {}\n",
    "test_digits: Digits = {}\n",
    "\n",
    "for key in cropClass.keys():\n",
    "  train_digits[key], test_digits[key] = train_test_split(cropClass[key], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "K = 1\n",
    "model_HOG = train_knn_model_HOG(train_digits, K)\n",
    "\n",
    "for cls in test_digits.keys():\n",
    "    predicts = model_HOG.predict(mod_HOG(test_digits[cls]))\n",
    "    print(cls, np.mean(predicts == cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Otsu’s algorithm and then the connected components to find the bounding box. I might not better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
